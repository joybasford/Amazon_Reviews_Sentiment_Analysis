{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries and initiate spark context\n",
    "from pyspark import SparkContext \n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sc = spark.sparkContext \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"ProductId\", StringType(), True),\n",
    "    StructField(\"UserId\", StringType(), True),\n",
    "    StructField(\"ProfileName\", StringType(), True),\n",
    "    StructField(\"Numerator\", IntegerType(), True),\n",
    "    StructField(\"Denominator\", IntegerType(), True),\n",
    "    StructField(\"Score\", IntegerType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Summary\", StringType(), True),\n",
    "    StructField(\"Text\", StringType(), True)])\n",
    "\n",
    "# load data into a pyspark DataFrame, observing schema\n",
    "df = spark.read.csv(\"hdfs://saltdean/data/reviews/Reviews.csv\",header= True,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Text|label|\n",
      "+--------------------+-----+\n",
      "|I have bought sev...|    5|\n",
      "|Product arrived l...|    1|\n",
      "|This is a confect...|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation \n",
    "import re\n",
    "def remove_punct(text):\n",
    "    no_punct = re.sub(r\"[^\\w\\s]\",\"\",text)\n",
    "    return no_punct\n",
    "\n",
    "# construct User Defined Function (UDF) to apply remove_punct function\n",
    "from pyspark.sql.functions import udf\n",
    "punct_remover = udf(lambda x: remove_punct(x))\n",
    "df = df.select(punct_remover('text'), 'Score')\n",
    "df = df.withColumnRenamed('<lambda>(text)', 'Text')\n",
    "df = df.withColumnRenamed('Score', 'label') # <<< this is to prevent 'Error: \"label\" does not exist' \n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+\n",
      "|summary|                Text|             label|\n",
      "+-------+--------------------+------------------+\n",
      "|  count|              568162|            568162|\n",
      "|   mean|1.2798334743042016E9| 4.176305349530591|\n",
      "| stddev| 7.996328434963414E7|1.3838779707236695|\n",
      "|    min|    Item arrived ...|                 0|\n",
      "|    max|zzzzzzz I had hig...|                69|\n",
      "+-------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove instances with Scores that are not integers, and are displayed as 'null'\n",
    "validScore = df.where(df[\"label\"].isNotNull())\n",
    "invalidScore = df.where(df[\"label\"].isNull()) \n",
    "\n",
    "# produce a new valid DataFrame using only the Text and Score columns\n",
    "valid = validScore.select(\"Text\",\"label\") # you can also switch to 'invalid' to see errors\n",
    "valid.describe().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores over 5: 248\n",
      "Number of scores less than 1: 1111\n",
      "Total number of instances: 568162\n",
      "Proportion of reviews with scores over 5: 0.04364952249534464\n",
      "Proportion of reviews with scores less than 1: 0.1955428205335802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Text: string, label: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note that the max label is 69, much higher than the specified max (5) \n",
    "# as well the min is equal to 0, lower than the specified min (1)\n",
    "# if these are not too many we want to remove them\n",
    "\n",
    "# count the number of labels greater than 5\n",
    "over5 = valid.filter(\"label >= 6\").count()\n",
    "print(\"Number of scores over 5:\", over5)\n",
    "\n",
    "# count the number of labels greater than 5\n",
    "less1 = valid.filter(\"label == 0\").count()\n",
    "print(\"Number of scores less than 1:\", less1)\n",
    "\n",
    "less1_df = valid.filter(\"label == 0\")\n",
    "\n",
    "# count the total number of labels\n",
    "total = valid.filter(\"label >= 0\").count()\n",
    "print(\"Total number of instances:\", total)\n",
    "\n",
    "# compute the proportion of over5 labels to total labels\n",
    "over5prop = (over5/total)*100\n",
    "print(\"Proportion of reviews with scores over 5:\", over5prop)\n",
    "\n",
    "less1prop = (less1/total)*100\n",
    "print(\"Proportion of reviews with scores less than 1:\", less1prop)\n",
    "\n",
    "display(less1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|summary|                Text|            label|\n",
      "+-------+--------------------+-----------------+\n",
      "|  count|              566803|           566803|\n",
      "|   mean|1.2641655634102564E9|4.179051628167105|\n",
      "| stddev| 9.690087336154778E7|1.314378260670736|\n",
      "|    min|    Item arrived ...|                1|\n",
      "|    max|zzzzzzz I had hig...|                5|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since the proportion of labels less than 1 and over 5 is only 0.19 and 0.43%, respectively. we'll exclude them by\n",
    "# filtering only for labels 1-5.\n",
    "valid5 = valid.filter(valid[\"label\"].between(1,5))\n",
    "valid5.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of less than 1: 0\n",
      "Number of 1 scores: 52635\n",
      "Number of 2 scores: 29877\n",
      "Number of 3 scores: 42502\n",
      "Number of 4 scores: 80141\n",
      "Number of 5 scores: 361648\n",
      "Number of over 5 : 0\n"
     ]
    }
   ],
   "source": [
    "# check for class imbalance\n",
    "\n",
    "# we can group the reviews by score by counting them within the DataFrame\n",
    "# it appears that there are many more '5' scores than any other score\n",
    "print(\"Number of less than 1:\",valid5.filter(\"label ==0\").count())\n",
    "print(\"Number of 1 scores:\",valid5.filter(\"label ==1\").count())\n",
    "print(\"Number of 2 scores:\",valid5.filter(\"label ==2\").count())\n",
    "print(\"Number of 3 scores:\",valid5.filter(\"label ==3\").count())\n",
    "print(\"Number of 4 scores:\",valid5.filter(\"label ==4\").count())\n",
    "print(\"Number of 5 scores:\",valid5.filter(\"label ==5\").count())\n",
    "print(\"Number of over 5 :\",valid5.filter(\"label > 5\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "chartsize": "50",
      "filter": "{}",
      "handlerId": "pieChart",
      "keyFields": "label",
      "legend": "false",
      "mpld3": "false",
      "no_margin": "true",
      "title": "Class Imbalance in label (Score) values"
     }
    }
   },
   "outputs": [],
   "source": [
    "# it's better to visualize this using Pixiedust\n",
    "import pixiedust\n",
    "display(valid5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 1: Naive Bayes\n",
    "\n",
    "# Step 1: construct pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# construct estimators\n",
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "ngrammer = NGram(n=2, inputCol=\"filtered\", outputCol=\"ngrams\") # << change n to {1,2,3}\n",
    "hashingTF = HashingTF(inputCol = \"ngrams\", outputCol = \"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "nb = NaiveBayes()\n",
    "\n",
    "# build the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, ngrammer, hashingTF, idf, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In Step 1, we tokenize the text and remove stop words, to further reduce \n",
    "# the noise. We convert the tokens ngrams and experiment with\n",
    "# different lengths of n. We believe that a larger n will improve the performance,\n",
    "# since sentiment is captured in conditionally dependent sequences of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Text: string, label: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: split the data into 80% training and 20% test set\n",
    "train,test = valid5.randomSplit([0.8,0.2], seed=100)\n",
    "# cache the training and test sets so that they don't have to be re-split each time\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: construct evaluator, selecting accuracy as the performance metric\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "# at this initial stage, we select accuracy, although we may look at precision and recall later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: introduce a Parameter Grid to iterate through different parameter values\n",
    "# including features for preprocessing (estimators) and Machine Learning algorithm\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(idf.minDocFreq,[10,100,1000]) \\\n",
    "    .addGrid(hashingTF.numFeatures, [1000,10000,100000]) \\\n",
    "    .addGrid(nb.smoothing,[0.1,0.5,1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Parameter selection\n",
    "# Parameter 1 [minDocFreq]: The fewer documents in which the term is found, the more relevant it is to \n",
    "# that document. We initialize with a range starting from 10, increasing \n",
    "# exponentially to 1000. \n",
    "# Parameter 2 [hashingTF]: this establishes a fixed feature vector spaced from which the term\n",
    "# frequency count can be computed and standardized. Each ngram is a feature so\n",
    "# the data runs into high dimensionality quickly. We initilize with a range\n",
    "# starting from 1000, increasing exponentially to 100000. \n",
    "# Parameter 3 [nb smoothing]: this prevents the algorithm from having a prior of zero when it encounters a new label. \n",
    "# The parameter is set by default to 1.0, but we will use employ a range from 0.1, 0.5 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: construct  model to fit to data\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "# We split the Training data by 80:20 to produce a Validation set\n",
    "tvs = TrainValidationSplit(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator,trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 s, sys: 1.57 s, total: 7.12 s\n",
      "Wall time: 18min 11s\n"
     ]
    }
   ],
   "source": [
    "# Step 6: fit the model\n",
    "%time tvsModel = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       4.0|    1|\n",
      "|       3.0|    5|\n",
      "|       4.0|    4|\n",
      "|       4.0|    5|\n",
      "|       4.0|    5|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test accuracy for Naive Bayes model: 0.10868035396984571\n",
      "CPU times: user 48 ms, sys: 16 ms, total: 64 ms\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: compute predictions on the training and test sets\n",
    "TvsTrain_predictions = tvsModel.transform(train)\n",
    "Tvstest_predictions = tvsModel.transform(test)\n",
    "\n",
    "# Step 8: visually inspect a sample of predicted labels along with true labels\n",
    "Tvstest_predictions.select(\"prediction\",\"label\").show(5)\n",
    "\n",
    "# Step 9: compute the accuracy for the training and test sets as well as time taken\n",
    "%time print (\"Test accuracy for Naive Bayes model:\",evaluator.evaluate(Tvstest_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, prediction: double, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can also display the predictions vs the ground truth labels at this point\n",
    "display(Tvstest_predictions.select(\"label\", \"prediction\", \"probability\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 10: create (prediction, label) pairs to compute additional metrics\n",
    "Pre_predict = Tvstest_predictions.select(\"label\", \"prediction\")\n",
    "Pre_predict = Pre_predict.selectExpr(\"cast(label as float) as label\", \"cast(prediction as float) as prediction\")\n",
    "Pre_predict.printSchema\n",
    "predictionRDD = Pre_predict.select(\"prediction\", \"label\").rdd\n",
    "type(predictionRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.10868035396984571\n",
      "Precision = 0.10868035396984571\n",
      "Accuracy = 0.10868035396984571\n"
     ]
    }
   ],
   "source": [
    "# Step 11: compute additional metrics, Precision and Recall, to compare with Accuracy\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(predictionRDD)\n",
    "\n",
    "# Summary stats\n",
    "print(\"Recall = %s\" % metrics.recall())\n",
    "print(\"Precision = %s\" % metrics.precision())\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='IDF_45838e19394bac471435', name='minDocFreq', doc='minimum number of documents in which a term should appear for filtering'): 1000,\n",
       " Param(parent='HashingTF_464f9812a7a87b010804', name='numFeatures', doc='number of features.'): 10000}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 12: to improve the model, we can search for the parameter map that produced\n",
    "# the best results in our validation set.\n",
    "\n",
    "def bestValidationParamters(vaidatedModel,parameterGrid):\n",
    "    \"\"\" Find the paramter map that produced the best outcome in our validation set \n",
    "        Positional arguments:\n",
    "        ~ validatedModel: the model returned by tvs.fit()\n",
    "        ~ parameterGrid: the parameterGrid used in the fitting\n",
    "    \"\"\"\n",
    "    # link the results to the parameter maps in the grid\n",
    "    metricParamPairs = zip(vaidatedModel.validationMetrics,parameterGrid)\n",
    "    # higher values are better in this case\n",
    "    bestMetric = 0 # we initialize with 0 as the minimum\n",
    "    # iterate through all tested parameter maps\n",
    "    for metric,params in metricParamPairs:\n",
    "        if metric > bestMetric: # if the metric is better than current best\n",
    "            bestParams = params # then keep the corresponding parameter map \n",
    "    return bestParams # and return the final best paramters\n",
    "\n",
    "bestValidationParamters(tvsModel,paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EXPERIMENT 2: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 2: logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Step 1: construct pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "ngrammer = NGram(n=2, inputCol=\"filtered\", outputCol=\"ngrams\") # use N=2 first\n",
    "hashingTF = HashingTF(inputCol = \"ngrams\", outputCol = \"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "lrPipeline = Pipeline(stages=[tokenizer,remover, ngrammer, hashingTF, idf, lr])\n",
    "\n",
    "# Step 2: we have already split the data \n",
    "# Step 3: we have already constructed out evaluator\n",
    "\n",
    "# Step 4: introduce a Parameter Grid to iterate through\n",
    "LRGrid = ParamGridBuilder() \\\n",
    "        .addGrid(lr.regParam, [0.1, 0.3, 0.5]) \\\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) \\\n",
    "             .build()\n",
    "            \n",
    "# Step 5: construct model to fit to the data            \n",
    "lrtvs = TrainValidationSplit(estimator = lrPipeline,\n",
    "                           estimatorParamMaps = LRGrid,\n",
    "                           evaluator = evaluator,\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 1.06 s, total: 4.4 s\n",
      "Wall time: 11min 49s\n"
     ]
    }
   ],
   "source": [
    "# Step 6: fit the model\n",
    "%time LrModel = lrtvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|    1|\n",
      "|       5.0|    5|\n",
      "|       5.0|    4|\n",
      "|       5.0|    5|\n",
      "|       5.0|    5|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "LR: Accuracy - testing: 0.783712461075632\n",
      "CPU times: user 44 ms, sys: 12 ms, total: 56 ms\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: compute predictions on the training and test sets\n",
    "LrTrain_predictions = LrModel.transform(train)\n",
    "LrTest_predictions = LrModel.transform(test)\n",
    "\n",
    "# Step 8: visually inspect a sample of predicted labels along with true labels\n",
    "LrTest_predictions.select(\"prediction\",\"label\").show(5)\n",
    "\n",
    "# Step 9: compute the accuracy for the training and test sets as well as time\n",
    "%time print (\"LR: Accuracy - testing:\",evaluator.evaluate(LrTest_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.10868035396984571\n",
      "Precision = 0.10868035396984571\n",
      "Accuracy = 0.10868035396984571\n"
     ]
    }
   ],
   "source": [
    "# Step 10: create (prediction, label) pairs to compute additional metrics\n",
    "Lr_predict = LrTest_predictions.select(\"label\", \"prediction\")\n",
    "Lr_predict = Pre_predict.selectExpr(\"cast(label as float) as label\", \"cast(prediction as float) as prediction\")\n",
    "Lr_predict.printSchema\n",
    "lrPredictionRDD = Lr_predict.select(\"prediction\", \"label\").rdd\n",
    "type(lrPredictionRDD)\n",
    "\n",
    "# Step 11: compute Precision and Recall, to compare with Accuracy\n",
    "lrmetrics = MulticlassMetrics(lrPredictionRDD)\n",
    "\n",
    "# Summary stats\n",
    "print(\"Recall = %s\" % lrmetrics.recall())\n",
    "print(\"Precision = %s\" % lrmetrics.precision())\n",
    "print(\"Accuracy = %s\" % lrmetrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_4353934741d75dc232c7', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       " Param(parent='LogisticRegression_4353934741d75dc232c7', name='regParam', doc='regularization parameter (>= 0).'): 0.5}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 12: to improve the model, we can search for the parameter map that produced\n",
    "# the best results in our validation set.\n",
    "\n",
    "bestValidationParamters(LrModel,LRGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the top words, 2-ngrams and  3-ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize and remove stop words with ngram\n",
    "# tokenize\n",
    "tok = Tokenizer(inputCol=\"Text\", outputCol=\"words\")\n",
    "review_tokenized = tok.transform(valid5)\n",
    "\n",
    "# remove stop words\n",
    "stopword_rm = StopWordsRemover(inputCol='words', outputCol='words_nsw')\n",
    "review_tokenized = stopword_rm.transform(review_tokenized)\n",
    "\n",
    "# add ngram column\n",
    "\n",
    "ngram = NGram(inputCol = 'words_nsw', outputCol = 'ngram', n = 3)\n",
    "add_ngram = ngram.transform(review_tokenized)\n",
    "\n",
    "# generate the top frequent ngram / filter only > 20\n",
    "ngrams = add_ngram.rdd.flatMap(lambda x: x[-1]).filter(lambda x: len(x.split())==n)\n",
    "ngram_tally = ngrams.map(lambda x: (x, 1))\\\n",
    "                      .reduceByKey(lambda x,y: x+y)\\\n",
    "                      .sortBy(lambda x: x[1], ascending=False)\\\n",
    "                      .filter(lambda x: x[1]>=20)\n",
    "ngram_list = ngram_tally.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('local grocery store', 2791),\n",
       " ('health food store', 1714),\n",
       " ('highly recommend product', 1709),\n",
       " ('cant go wrong', 1428),\n",
       " ('high fructose corn', 1409)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_tally.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add ngram column\n",
    "\n",
    "ngram1 = NGram(inputCol = 'words_nsw', outputCol = 'ngram', n = 2)\n",
    "add_ngram1 = ngram.transform(review_tokenized)\n",
    "\n",
    "# generate the top frequent ngram / filter only > 20\n",
    "ngrams1 = add_ngram1.rdd.flatMap(lambda x: x[-1]).filter(lambda x: len(x.split())==n)\n",
    "ngram_tally1 = ngrams1.map(lambda x: (x, 1))\\\n",
    "                      .reduceByKey(lambda x,y: x+y)\\\n",
    "                      .sortBy(lambda x: x[1], ascending=False)\\\n",
    "                      .filter(lambda x: x[1]>=20)\n",
    "ngram_list1 = ngram_tally1.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' highly recommend', 4407),\n",
       " (' dont know', 1946),\n",
       " (' ive tried', 1776),\n",
       " ('subscribe  save', 1527),\n",
       " ('cup coffee ', 1331)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_tally1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' highly recommend',\n",
       " ' dont know',\n",
       " ' ive tried',\n",
       " 'subscribe  save',\n",
       " 'cup coffee ',\n",
       " 'grocery store ',\n",
       " ' great product',\n",
       " 'give try ',\n",
       " ' im sure',\n",
       " ' highly recommended',\n",
       " ' tastes like',\n",
       " 'dog food ',\n",
       " 'really good ',\n",
       " 'great product ',\n",
       " 'peanut butter ',\n",
       " 'tastes great ',\n",
       " 'taste good ',\n",
       " 'taste great ',\n",
       " 'long time ',\n",
       " 'love product ',\n",
       " ' really like',\n",
       " ' much better',\n",
       " ' dont think',\n",
       " 'every day ',\n",
       " ' dont like',\n",
       " 'ever tasted ',\n",
       " ' also like',\n",
       " ' im glad',\n",
       " 'green tea ',\n",
       " ' tastes great',\n",
       " 'great price ',\n",
       " ' taste like',\n",
       " 'pretty good ',\n",
       " ' taste great',\n",
       " 'years ago ',\n",
       " ' hard find',\n",
       " 'much better ',\n",
       " 'love tea ',\n",
       " 'ive tried ',\n",
       " ' thanks amazon',\n",
       " 'cat food ',\n",
       " 'love stuff ',\n",
       " ' first time',\n",
       " 'gluten free ',\n",
       " ' cant wait',\n",
       " ' definitely recommend',\n",
       " ' great flavor',\n",
       " 'free shipping ',\n",
       " ' even though',\n",
       " ' really good',\n",
       " 'ive ever ',\n",
       " ' great price',\n",
       " ' kids love',\n",
       " ' definitely buy',\n",
       " ' im going',\n",
       " 'tastes good ',\n",
       " ' make sure',\n",
       " ' havent tried',\n",
       " ' taste good',\n",
       " 'coffee maker ',\n",
       " 'salt  vinegar',\n",
       " 'great flavor ',\n",
       " ' recommend anyone',\n",
       " 'sea salt ',\n",
       " 'dogs love ',\n",
       " ' dog loves',\n",
       " ' great taste',\n",
       " 'good price ',\n",
       " ' dogs love',\n",
       " 'love coffee ',\n",
       " ' tried many',\n",
       " 'great taste ',\n",
       " 'dog loves ',\n",
       " 'highly recommend ',\n",
       " 'iced tea ',\n",
       " ' also great',\n",
       " 'really like ',\n",
       " ' cant find',\n",
       " 'grocery stores ',\n",
       " ' im happy',\n",
       " 'every morning ',\n",
       " ' also use',\n",
       " ' cant beat',\n",
       " ' ive never',\n",
       " ' tastes good',\n",
       " 'one favorites ',\n",
       " 'dark chocolate ',\n",
       " 'find amazon ',\n",
       " ' br br',\n",
       " ' give try',\n",
       " 'loves treats ',\n",
       " 'absolutely delicious ',\n",
       " 'subscribe save ',\n",
       " ' good price',\n",
       " ' recommend product',\n",
       " ' ive used',\n",
       " ' one thing',\n",
       " ' thank amazon',\n",
       " 'ever eaten ',\n",
       " ' also love',\n",
       " ' right amount',\n",
       " 'made china ',\n",
       " ' pleasantly surprised',\n",
       " 'local stores ',\n",
       " 'good product ',\n",
       " 'hot chocolate ',\n",
       " 'dry food ',\n",
       " ' dont get',\n",
       " ' next time',\n",
       " 'found amazon ',\n",
       " 'good flavor ',\n",
       " 'every time ',\n",
       " 'potato chips ',\n",
       " ' well worth',\n",
       " 'like coffee ',\n",
       " 'ever since ',\n",
       " 'flavored coffee ',\n",
       " '5 stars ',\n",
       " ' seems like',\n",
       " 'even better ',\n",
       " 'good stuff ',\n",
       " ' easy use',\n",
       " ' like strong',\n",
       " ' good flavor',\n",
       " ' far best',\n",
       " 'ice cream ',\n",
       " ' great way',\n",
       " ' definitely order',\n",
       " 'kids love ',\n",
       " 'olive oil ',\n",
       " ' good product',\n",
       " ' one best',\n",
       " ' great deal',\n",
       " 'mac  cheese',\n",
       " 'hard find ',\n",
       " 'ever tried ',\n",
       " ' tried several',\n",
       " ' needless say',\n",
       " 'hot water ',\n",
       " 'great deal ',\n",
       " ' makes great',\n",
       " ' decided try',\n",
       " 'corn syrup ',\n",
       " ' best part',\n",
       " 'absolutely love ',\n",
       " ' gluten free',\n",
       " ' like coffee',\n",
       " ' great snack',\n",
       " ' dont even',\n",
       " ' easy make',\n",
       " ' also good',\n",
       " 'black tea ',\n",
       " 'tea bags ',\n",
       " 'right away ',\n",
       " ' looks like',\n",
       " ' absolutely love',\n",
       " ' love taste',\n",
       " 'get enough ',\n",
       " 'love treats ',\n",
       " 'coconut water ',\n",
       " 'coconut oil ',\n",
       " 'good coffee ',\n",
       " ' cant get',\n",
       " ' doesnt taste',\n",
       " ' dont want',\n",
       " 'many years ',\n",
       " 'far favorite ',\n",
       " 'anything else ',\n",
       " ' cant say',\n",
       " ' peanut butter',\n",
       " 'per serving ',\n",
       " 'find stores ',\n",
       " ' even better',\n",
       " ' cant go',\n",
       " 'bitter taste ',\n",
       " ' whole family',\n",
       " 'easy make ',\n",
       " 'coffee  like',\n",
       " 'months ago ',\n",
       " 'love food ',\n",
       " 'real thing ',\n",
       " ' ive also',\n",
       " 'strong coffee ',\n",
       " ' couldnt find',\n",
       " ' youre looking',\n",
       " 'reasonable price ',\n",
       " ' tasted like',\n",
       " ' never buy',\n",
       " ' happy find',\n",
       " 'baby food ',\n",
       " 'easy use ',\n",
       " ' love product',\n",
       " 'taste like ',\n",
       " ' works great',\n",
       " ' wont disappointed',\n",
       " 'healthy snack ',\n",
       " ' like fact',\n",
       " ' dont buy',\n",
       " 'decided try ',\n",
       " 'excellent product ',\n",
       " ' one favorite',\n",
       " 'br update ',\n",
       " ' good stuff',\n",
       " 'one best ',\n",
       " 'good  like',\n",
       " 'loves food ',\n",
       " 'several years ',\n",
       " ' add little',\n",
       " 'cup tea ',\n",
       " 'scalp  hair',\n",
       " 'waste money ',\n",
       " 'far best ',\n",
       " 'first time ',\n",
       " 'taste  like',\n",
       " 'pleasantly surprised ',\n",
       " ' used buy',\n",
       " 'one sitting ',\n",
       " ' definitely worth',\n",
       " ' great value',\n",
       " 'like taste ',\n",
       " ' subscribe save',\n",
       " ' dont waste',\n",
       " 'salt  pepper',\n",
       " 'canned food ',\n",
       " ' ive found',\n",
       " 'great coffee ',\n",
       " 'works great ',\n",
       " ' wont buy',\n",
       " 'recommend product ',\n",
       " ' love fact',\n",
       " ' make great',\n",
       " ' read reviews',\n",
       " ' continue buy',\n",
       " 'long way ',\n",
       " 'quite good ',\n",
       " ' also used',\n",
       " ' price great',\n",
       " ' price right',\n",
       " 'good thing ',\n",
       " 'flavor  like',\n",
       " ' price amazon',\n",
       " ' especially like',\n",
       " 'good taste ',\n",
       " ' feel like',\n",
       " ' price good',\n",
       " ' glad find',\n",
       " ' waste money',\n",
       " ' love flavor',\n",
       " 'chocolate flavor ',\n",
       " 'love taste ',\n",
       " ' dont care',\n",
       " 'flavor  great',\n",
       " ' really enjoy',\n",
       " 'full flavor ',\n",
       " ' little bit',\n",
       " 'dog treats ',\n",
       " 'love flavor ',\n",
       " 'worth money ',\n",
       " 'didnt like ',\n",
       " ' green tea',\n",
       " ' little pricey',\n",
       " ' dont use',\n",
       " 'picky eater ',\n",
       " ' great tasting',\n",
       " ' works well',\n",
       " 'stop eating ',\n",
       " ' flavor good',\n",
       " ' look forward',\n",
       " ' weve tried',\n",
       " ' cant believe',\n",
       " 'food store ',\n",
       " ' feel good',\n",
       " ' finally found',\n",
       " ' every time',\n",
       " 'great snack ',\n",
       " 'favorite flavor ',\n",
       " ' thank goodness',\n",
       " 'regular basis ',\n",
       " 'dont know ',\n",
       " ' smells like',\n",
       " 'quality product ',\n",
       " 'dont like ',\n",
       " 'flavor  love',\n",
       " ' like taste',\n",
       " ' love coffee',\n",
       " 'years old ',\n",
       " 'made usa ',\n",
       " 'great value ',\n",
       " ' save money',\n",
       " 'something else ',\n",
       " ' pretty good',\n",
       " 'local store ',\n",
       " 'great  like',\n",
       " 'last year ',\n",
       " 'way go ',\n",
       " ' good thing',\n",
       " 'whole foods ',\n",
       " ' high quality',\n",
       " ' amazon great',\n",
       " 'save money ',\n",
       " 'next day ',\n",
       " 'flavor  also',\n",
       " ' theyre good',\n",
       " ' love stuff',\n",
       " 'taste buds ',\n",
       " ' free shipping',\n",
       " ' glad found',\n",
       " ' must say',\n",
       " ' also tried',\n",
       " ' im big',\n",
       " ' hard time',\n",
       " 'fell love ',\n",
       " ' didnt like',\n",
       " ' husband loves',\n",
       " 'ive found ',\n",
       " ' one day',\n",
       " ' really great',\n",
       " 'product great ',\n",
       " ' try youll',\n",
       " 'sour cream ',\n",
       " ' cats love',\n",
       " ' 5 stars',\n",
       " ' dont need',\n",
       " 'good deal ',\n",
       " 'buy supermarket ',\n",
       " 'like much ',\n",
       " ' brown rice',\n",
       " 'really liked ',\n",
       " ' product arrived',\n",
       " 'order amazon ',\n",
       " ' dont feel',\n",
       " 'available amazon ',\n",
       " 'health benefits ',\n",
       " ' cant even',\n",
       " ' first tried',\n",
       " 'go wrong ',\n",
       " 'love  great',\n",
       " 'worth price ',\n",
       " ' found amazon',\n",
       " 'per day ',\n",
       " ' great stuff',\n",
       " ' dark chocolate',\n",
       " 'earl grey ',\n",
       " ' quick easy',\n",
       " 'coffee  coffee',\n",
       " ' difficult find',\n",
       " ' much cheaper',\n",
       " 'kind way ',\n",
       " ' good deal',\n",
       " 'love chips ',\n",
       " 'br consbr ',\n",
       " 'beef jerky ',\n",
       " ' green mountain',\n",
       " ' arrived quickly',\n",
       " 'family loves ',\n",
       " ' wont buying',\n",
       " 'cats love ',\n",
       " ' im really',\n",
       " 'coffee flavor ',\n",
       " 'taste texture ',\n",
       " 'morning coffee ',\n",
       " ' friskies nine',\n",
       " ' love love',\n",
       " 'way  ground',\n",
       " 'instant coffee ',\n",
       " 'lives kit ',\n",
       " 'kit  kaboodle',\n",
       " 'supermarket  friskies',\n",
       " 'works well ',\n",
       " ' ground slaughterhouse',\n",
       " ' kaboodle stuff',\n",
       " '5 minutes ',\n",
       " 'variety pack ',\n",
       " ' tried one',\n",
       " 'half  half',\n",
       " 'stopped carrying ',\n",
       " 'coffee  tried',\n",
       " ' perfect size',\n",
       " 'good  love',\n",
       " 'cant beat ',\n",
       " ' dont drink',\n",
       " ' great coffee',\n",
       " 'french roast ',\n",
       " ' good quality',\n",
       " 'product  great',\n",
       " ' definitely purchase',\n",
       " ' love tea',\n",
       " 'perfect condition ',\n",
       " ' absolutely delicious',\n",
       " ' also add',\n",
       " 'flavor  really',\n",
       " 'timely manner ',\n",
       " 'clear scalp ',\n",
       " 'customer service ',\n",
       " ' buy product',\n",
       " 'hot cold ',\n",
       " 'good quality ',\n",
       " ' price reasonable',\n",
       " 'taste better ',\n",
       " 'tea  like',\n",
       " 'hot sauce ',\n",
       " 'eat one ',\n",
       " ' flavor great',\n",
       " 'different flavors ',\n",
       " ' either way',\n",
       " 'coffee ever ',\n",
       " 'stuff great ',\n",
       " 'marley coffee ',\n",
       " 'per bag ',\n",
       " 'coffee  love',\n",
       " 'months old ',\n",
       " ' hair beauty',\n",
       " ' good value',\n",
       " 'absolutely loves ',\n",
       " 'well worth ',\n",
       " 'good condition ',\n",
       " 'pet store ',\n",
       " 'fruit  nut',\n",
       " ' product great',\n",
       " 'overly sweet ',\n",
       " 'one day ',\n",
       " 'k cups ',\n",
       " 'every month ',\n",
       " 'order online ',\n",
       " ' vinegar chips',\n",
       " 'high quality ',\n",
       " 'find locally ',\n",
       " 'like product ',\n",
       " ' oh well',\n",
       " '6 months ',\n",
       " ' really liked',\n",
       " 'coffee  tea',\n",
       " ' went back',\n",
       " 'last long ',\n",
       " ' excellent product',\n",
       " 'fits bill ',\n",
       " 'im glad ',\n",
       " ' much easier',\n",
       " 'flavored coffees ',\n",
       " ' thought id',\n",
       " 'expiration date ',\n",
       " ' looking forward',\n",
       " 'good value ',\n",
       " ' good taste',\n",
       " 'sweet taste ',\n",
       " 'medium roast ',\n",
       " ' thrilled find',\n",
       " 'like  like',\n",
       " ' best price',\n",
       " ' ill stick',\n",
       " 'candy bar ',\n",
       " 'coffee  great',\n",
       " 'tea bag ',\n",
       " ' ive bought',\n",
       " 'gave try ',\n",
       " 'loves stuff ',\n",
       " 'tasted great ',\n",
       " ' still good',\n",
       " 'fit bill ',\n",
       " ' expiration date',\n",
       " ' didnt even',\n",
       " ' tried flavors',\n",
       " 'happy product ',\n",
       " ' really taste',\n",
       " ' ive always',\n",
       " 'bitter aftertaste ',\n",
       " 'br prosbr ',\n",
       " 'buy product ',\n",
       " ' theyre great',\n",
       " 'hot cocoa ',\n",
       " 'sweet tooth ',\n",
       " ' wish came',\n",
       " 'dark roast ',\n",
       " 'higgins  burke',\n",
       " 'start day ',\n",
       " ' dont mind',\n",
       " 'highly recommended ',\n",
       " 'personal thing ',\n",
       " ' ive using',\n",
       " ' ive ordered',\n",
       " 'product  love',\n",
       " ' best thing',\n",
       " 'favorite tea ',\n",
       " ' wish amazon',\n",
       " ' best tasting',\n",
       " ' nice flavor',\n",
       " ' save program',\n",
       " 'bottom line ',\n",
       " 'bold coffee ',\n",
       " 'flavor  dont',\n",
       " 'coffee  good',\n",
       " ' tried brands',\n",
       " 'natural ingredients ',\n",
       " 'love cookies ',\n",
       " 'coffee drinker ',\n",
       " 'flavor coffee ',\n",
       " 'good  dont',\n",
       " ' amazon best',\n",
       " '2 years ',\n",
       " 'sugar free ',\n",
       " 'great  love',\n",
       " ' amazons price',\n",
       " ' buyer beware',\n",
       " ' dont understand',\n",
       " ' continue purchase',\n",
       " 'price right ',\n",
       " ' bottom line',\n",
       " 'coffee  one',\n",
       " ' dont taste',\n",
       " ' usually buy',\n",
       " ' im still',\n",
       " ' id say',\n",
       " ' really nice',\n",
       " 'great tasting ',\n",
       " ' really enjoyed',\n",
       " ' keep mind',\n",
       " 'flavor  im',\n",
       " ' like much',\n",
       " ' sea salt',\n",
       " 'taste  also',\n",
       " ' 100 calories',\n",
       " 'like tea ',\n",
       " 'great stuff ',\n",
       " ' one bag',\n",
       " 'chai tea ',\n",
       " 'per box ',\n",
       " 'like flavor ',\n",
       " ' really love',\n",
       " ' dont worry',\n",
       " ' next day',\n",
       " 'product  use',\n",
       " ' tried every',\n",
       " 'tasted good ',\n",
       " 'flavor great ',\n",
       " 'maple syrup ',\n",
       " ' like flavor',\n",
       " 'buy amazon ',\n",
       " 'still good ',\n",
       " 'taste  dont',\n",
       " 'granola bars ',\n",
       " ' nothing like',\n",
       " 'disappointed product ',\n",
       " ' realize taste',\n",
       " '10 years ',\n",
       " 'amazons subscribe ',\n",
       " 'taste  realize',\n",
       " 'calories fat ',\n",
       " 'tea  love',\n",
       " 'wonderful product ',\n",
       " 'good  taste',\n",
       " 'favorite coffee ',\n",
       " ' also make',\n",
       " 'thing  thats',\n",
       " ' bit pricey',\n",
       " ' dont expect',\n",
       " 'good  im',\n",
       " 'one favorite ',\n",
       " 'good  also',\n",
       " ' dog food',\n",
       " ' worth every',\n",
       " 'next time ',\n",
       " 'tea ever ',\n",
       " 'taste  great',\n",
       " ' much prefer',\n",
       " 'dog foods ',\n",
       " ' tea one',\n",
       " ' last time',\n",
       " ' bit expensive',\n",
       " ' dont eat',\n",
       " 'mouth  much',\n",
       " ' good coffee',\n",
       " ' great alternative',\n",
       " ' think great',\n",
       " 'times day ',\n",
       " ' thats make',\n",
       " ' id recommend',\n",
       " 'easy prepare ',\n",
       " 'flavor good ',\n",
       " ' im fan',\n",
       " 'several times ',\n",
       " 'wonderful flavor ',\n",
       " ' family loves',\n",
       " 'year old ',\n",
       " ' second time',\n",
       " '4 stars ',\n",
       " 'fast shipping ',\n",
       " ' another reviewer',\n",
       " ' much simply',\n",
       " ' bought case',\n",
       " 'safe mouth ',\n",
       " 'find anywhere ',\n",
       " 'food allergies ',\n",
       " ' got home',\n",
       " '2nd taste ',\n",
       " 'flavor  one',\n",
       " ' also dont',\n",
       " 'ever used ',\n",
       " 'tastes like ',\n",
       " 'coffee good ',\n",
       " 'one time ',\n",
       " ' wasnt sure',\n",
       " ' think ill',\n",
       " 'roast coffee ',\n",
       " ' add water',\n",
       " ' one favorites',\n",
       " 'nice flavor ',\n",
       " 'cream  onion',\n",
       " 'tasting coffee ',\n",
       " ' easy prepare',\n",
       " 'really great ',\n",
       " 'price amazon ',\n",
       " ' first thought',\n",
       " ' one cat',\n",
       " ' first thing',\n",
       " ' fast shipping',\n",
       " 'new favorite ',\n",
       " ' decided give',\n",
       " ' recommend highly',\n",
       " 'get pay ',\n",
       " ' youll find',\n",
       " 'kind bars ',\n",
       " ' pretty much',\n",
       " 'couple years ',\n",
       " ' didnt know',\n",
       " 'tea  great',\n",
       " ' didnt think',\n",
       " 'arrived quickly ',\n",
       " 'flavor  definitely',\n",
       " ' buy case',\n",
       " 'best price ',\n",
       " ' almost like',\n",
       " 'special treat ',\n",
       " 'best ever ',\n",
       " 'real deal ',\n",
       " 'tortilla chips ',\n",
       " ' usually drink',\n",
       " ' love much',\n",
       " 'food  also',\n",
       " ' reading reviews',\n",
       " ' internet research',\n",
       " ' ill definitely',\n",
       " 'regular coffee ',\n",
       " ' far favorite',\n",
       " ' dont really',\n",
       " 'like one ',\n",
       " ' little expensive',\n",
       " 'good  however',\n",
       " 'like  dont',\n",
       " 'twice day ',\n",
       " ' wont eat',\n",
       " 'sweet potato ',\n",
       " ' small size',\n",
       " ' low fat',\n",
       " 'hot tea ',\n",
       " ' also makes',\n",
       " 'tea drinker ',\n",
       " ' thank much',\n",
       " ' like better',\n",
       " 'upset stomach ',\n",
       " ' grocery store',\n",
       " ' even tried',\n",
       " 'bad batch ',\n",
       " 'artificial sweeteners ',\n",
       " ' also noticed',\n",
       " 'added sugar ',\n",
       " 'good way ',\n",
       " 'keurig brewer ',\n",
       " 'better price ',\n",
       " ' overly sweet',\n",
       " 'good  good',\n",
       " ' new favorite',\n",
       " 'many times ',\n",
       " ' gave 4',\n",
       " 'every penny ',\n",
       " 'ice tea ',\n",
       " 'ingredient list ',\n",
       " 'like cardboard ',\n",
       " ' good tasting',\n",
       " ' didnt taste',\n",
       " 'really enjoy ',\n",
       " ' low calories',\n",
       " ' little goes',\n",
       " ' son loves',\n",
       " 'really enjoyed ',\n",
       " 'food  cats',\n",
       " ' took one',\n",
       " 'flavor texture ',\n",
       " 'time day ',\n",
       " 'taste  love',\n",
       " ' local grocery',\n",
       " 'serving size ',\n",
       " ' big fan',\n",
       " ' use make',\n",
       " ' customer service',\n",
       " ' id rather',\n",
       " 'delicious  love',\n",
       " 'coffee  strong',\n",
       " ' never seen',\n",
       " 'much flavor ',\n",
       " 'low fat ',\n",
       " ' ill probably',\n",
       " 'br 1 ',\n",
       " 'taste wonderful ',\n",
       " 'one try ',\n",
       " 'wouldnt eat ',\n",
       " 'flavor  good',\n",
       " ' im disappointed',\n",
       " 'coffee  also',\n",
       " 'product  like',\n",
       " ' big deal',\n",
       " ' one dogs',\n",
       " 'quite tasty ',\n",
       " 'product good ',\n",
       " ' im hoping',\n",
       " ' usually use',\n",
       " 'amazon  great',\n",
       " ' cant imagine',\n",
       " 'worth try ',\n",
       " ' however like',\n",
       " ' use one',\n",
       " 'tea  tea',\n",
       " 'love salt ',\n",
       " 'price great ',\n",
       " 'little flavor ',\n",
       " 'love bars ',\n",
       " 'vanilla flavor ',\n",
       " 'delicious  like',\n",
       " ' theyre also',\n",
       " ' taste texture',\n",
       " 'big hit ',\n",
       " ' good buy',\n",
       " ' ive made',\n",
       " 'throughout day ',\n",
       " 'flavor  use',\n",
       " ' drink coffee',\n",
       " ' also bought',\n",
       " 'coffee  dont',\n",
       " ' also get',\n",
       " ' cant tell',\n",
       " ' coffee good',\n",
       " 'work well ',\n",
       " ' good way',\n",
       " 'time  also',\n",
       " 'year ago ',\n",
       " 'local supermarket ',\n",
       " 'taste  taste',\n",
       " 'lose weight ',\n",
       " ' wish find',\n",
       " 'brown rice ',\n",
       " 'saturated fat ',\n",
       " ' definitely ordering',\n",
       " 'brown sugar ',\n",
       " '10 minutes ',\n",
       " '2 months ',\n",
       " ' best way',\n",
       " 'tell difference ',\n",
       " ' happy see',\n",
       " ' eat one',\n",
       " ' low calorie',\n",
       " 'soy milk ',\n",
       " ' give 5',\n",
       " ' like eating',\n",
       " ' guess ill',\n",
       " ' shipping fast',\n",
       " 'right door ',\n",
       " 'excellent condition ',\n",
       " 'try  youll',\n",
       " 'good  nice',\n",
       " ' wonderful flavor',\n",
       " ' worked well',\n",
       " ' im hooked',\n",
       " 'vet  internet',\n",
       " 'ask vet ',\n",
       " ' bought one',\n",
       " 'one bag ',\n",
       " ' im trying',\n",
       " 'great  dont',\n",
       " 'try one ',\n",
       " 'ordered amazon ',\n",
       " ' doesnt smell',\n",
       " 'well packaged ',\n",
       " ' sweet enough',\n",
       " 'good  ive',\n",
       " 'per cup ',\n",
       " 'big deal ',\n",
       " ' bought two',\n",
       " 'absolutely loved ',\n",
       " 'salad dressing ',\n",
       " 'youll love ',\n",
       " ' also really',\n",
       " ' really dont',\n",
       " 'product  tastes',\n",
       " 'definitely buy ',\n",
       " ' individually wrapped',\n",
       " ' never tried',\n",
       " ' hope amazon',\n",
       " 'taste  good',\n",
       " ' wont regret',\n",
       " 'love love ',\n",
       " ' go back',\n",
       " 'also good ',\n",
       " ' ordered two',\n",
       " ' worth price',\n",
       " 'product  however',\n",
       " 'baked goods ',\n",
       " ' good luck',\n",
       " 'best far ',\n",
       " ' ill buy',\n",
       " 'whole bag ',\n",
       " ' really really',\n",
       " ' cant eat',\n",
       " 'every bite ',\n",
       " ' also nice',\n",
       " 'jet fuel ',\n",
       " ' product good',\n",
       " 'good  really',\n",
       " 'artificial sweetener ',\n",
       " ' strongly recommend',\n",
       " 'weve tried ',\n",
       " 'taste coffee ',\n",
       " 'food  ive',\n",
       " 'without bitterness ',\n",
       " 'breakfast blend ',\n",
       " 'wont eat ',\n",
       " ' great buy',\n",
       " ' cat loves',\n",
       " ' reason gave',\n",
       " 'great  also',\n",
       " 'low calories ',\n",
       " 'coffee  however',\n",
       " 'throw away ',\n",
       " 'price good ',\n",
       " 'dont care ',\n",
       " '20 minutes ',\n",
       " 'energy drink ',\n",
       " 'recommend anyone ',\n",
       " ' ive even',\n",
       " 'love  love',\n",
       " 'taste  im',\n",
       " 'good go ',\n",
       " ' first ingredient',\n",
       " 'save program ',\n",
       " 'delivered door ',\n",
       " 'good  great',\n",
       " 'grams fat ',\n",
       " ' dont let',\n",
       " ' delighted find',\n",
       " 'potato chip ',\n",
       " ' daughter loves',\n",
       " ' ill ordering',\n",
       " ' nothing else',\n",
       " ' favorite flavor',\n",
       " 'wont disappointed ',\n",
       " 'reasonably priced ',\n",
       " 'taste  one',\n",
       " ' best coffee',\n",
       " 'coffee  im',\n",
       " 'rich flavor ',\n",
       " 'one box ',\n",
       " ' first bite',\n",
       " ' ill try',\n",
       " ' also found',\n",
       " 'sensitive stomach ',\n",
       " 'less expensive ',\n",
       " ' happy product',\n",
       " 'every night ',\n",
       " ' thanks much',\n",
       " ' definitely buying',\n",
       " 'green teas ',\n",
       " 'tea  im',\n",
       " 'chocolate chips ',\n",
       " 'something different ',\n",
       " 'coffee great ',\n",
       " ' sweet potato',\n",
       " 'tea  ive',\n",
       " 'tea  one',\n",
       " 'time  love',\n",
       " 'keep fresh ',\n",
       " ' ordered case',\n",
       " 'tea  drink',\n",
       " 'loves  great',\n",
       " ' ive gotten',\n",
       " 'product  good',\n",
       " 'good choice ',\n",
       " 'fat calories ',\n",
       " ' bad thing',\n",
       " ' really cant',\n",
       " 'try flavors ',\n",
       " ' much like',\n",
       " ' happy purchase',\n",
       " 'love  also',\n",
       " ' looking something',\n",
       " ' perfect blend',\n",
       " ' even husband',\n",
       " 'favorite  like',\n",
       " 'love cereal ',\n",
       " ' im looking',\n",
       " 'great  use',\n",
       " ' felt like',\n",
       " ' bitter taste',\n",
       " ' go wrong',\n",
       " 'like food ',\n",
       " 'trader joes ',\n",
       " 'really delicious ',\n",
       " ' give one',\n",
       " 'great tea ',\n",
       " 'coffee taste ',\n",
       " 'really likes ',\n",
       " 'ever found ',\n",
       " 'keurig machine ',\n",
       " 'good one ',\n",
       " ' ive got',\n",
       " ' stay away',\n",
       " ' ive drinking',\n",
       " 'taste  use',\n",
       " ' also made',\n",
       " 'worked well ',\n",
       " ' kind like',\n",
       " 'quality ingredients ',\n",
       " 'decaf coffee ',\n",
       " ' thanks great',\n",
       " ' think good',\n",
       " 'energy drinks ',\n",
       " ' one box',\n",
       " ' didnt notice',\n",
       " ' like bold',\n",
       " 'packaged well ',\n",
       " 'ever made ',\n",
       " ' ordered amazon',\n",
       " ' ive buying',\n",
       " ' everyone loves',\n",
       " ' coffee people',\n",
       " ' drink lot',\n",
       " 'tea  good',\n",
       " 'absolutely wonderful ',\n",
       " 'daughter loves ',\n",
       " ' able find',\n",
       " ' amazon price',\n",
       " ' want something',\n",
       " ' used make',\n",
       " 'product  also',\n",
       " 'food  one',\n",
       " 'cat loves ',\n",
       " 'get amazon ',\n",
       " ' gave one',\n",
       " ' happy found',\n",
       " ' love chocolate',\n",
       " 'favorite treat ',\n",
       " 'real treat ',\n",
       " 'good tea ',\n",
       " 'happy purchase ',\n",
       " 'great idea ',\n",
       " 'shelf life ',\n",
       " 'nutritional value ',\n",
       " 'good tasting ',\n",
       " 'pill pockets ',\n",
       " ' serving size',\n",
       " 'itbr br ',\n",
       " ' wonderful product',\n",
       " ' love amazon',\n",
       " 'tastes wonderful ',\n",
       " ' started using',\n",
       " ' eat whole',\n",
       " 'graham crackers ',\n",
       " 'half price ',\n",
       " '15 minutes ',\n",
       " ' didnt realize',\n",
       " 'able find ',\n",
       " ' followed directions',\n",
       " ' first one',\n",
       " ' youll love',\n",
       " 'chicken flavor ',\n",
       " ' one good',\n",
       " 'time time ',\n",
       " ' ever since',\n",
       " 'two years ',\n",
       " 'isnt bad ',\n",
       " 'try  wont',\n",
       " 'walked away ',\n",
       " 'try product ',\n",
       " 'iced coffee ',\n",
       " ' many people',\n",
       " 'quite time ',\n",
       " ' way better',\n",
       " ' really wanted',\n",
       " ' continue order',\n",
       " 'milk chocolate ',\n",
       " ' drinking tea',\n",
       " 'price reasonable ',\n",
       " ' havent found',\n",
       " 'two days ',\n",
       " ' added bonus',\n",
       " ' full flavor',\n",
       " 'product amazon ',\n",
       " 'br 2 ',\n",
       " ' upon opening',\n",
       " ' health benefits',\n",
       " 'flavor  tried',\n",
       " 'really well ',\n",
       " 'coffee shop ',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ngram_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top words\n",
    "\n",
    "ngram = NGram(inputCol = 'words_nsw', outputCol = 'ngram', n = 1)\n",
    "add_ngram2 = ngram.transform(review_tokenized)\n",
    "\n",
    "# generate the top frequent ngram / filter only > 20\n",
    "words = add_ngram2.rdd.flatMap(lambda x: x[-1]).filter(lambda x: len(x.split())==1)\n",
    "words_tally = words.map(lambda x: (x, 1))\\\n",
    "                      .reduceByKey(lambda x,y: x+y)\\\n",
    "                      .sortBy(lambda x: x[1], ascending=False)\\\n",
    "                      .filter(lambda x: x[1]>=20)\n",
    "words_list = ngram_tally.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 220988),\n",
       " ('br', 198214),\n",
       " ('good', 174872),\n",
       " ('great', 152200),\n",
       " ('one', 151099),\n",
       " ('taste', 148361),\n",
       " ('coffee', 143019),\n",
       " ('product', 131056),\n",
       " ('flavor', 126153),\n",
       " ('love', 119202),\n",
       " ('tea', 119164),\n",
       " ('food', 106526),\n",
       " ('get', 94531),\n",
       " ('really', 88636),\n",
       " ('dont', 81749),\n",
       " ('much', 80080),\n",
       " ('also', 73272),\n",
       " ('little', 73152),\n",
       " ('use', 72956),\n",
       " ('time', 72272),\n",
       " ('amazon', 70194),\n",
       " ('tried', 70069),\n",
       " ('best', 69340),\n",
       " ('buy', 68024),\n",
       " ('price', 66546),\n",
       " ('find', 65573),\n",
       " ('ive', 64902),\n",
       " ('im', 64827),\n",
       " ('even', 63180),\n",
       " ('make', 62382),\n",
       " ('well', 61262),\n",
       " ('better', 59768),\n",
       " ('try', 59197),\n",
       " ('eat', 58933),\n",
       " ('dog', 58000),\n",
       " ('first', 54757),\n",
       " ('chocolate', 51237),\n",
       " ('water', 48616),\n",
       " ('found', 48267),\n",
       " ('bag', 48241),\n",
       " ('used', 48099),\n",
       " ('bought', 46881),\n",
       " ('sugar', 44183),\n",
       " ('sweet', 44134),\n",
       " ('drink', 43816),\n",
       " ('made', 43297),\n",
       " ('cup', 43201),\n",
       " ('box', 42506),\n",
       " ('two', 41706),\n",
       " ('think', 41388)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tally.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
